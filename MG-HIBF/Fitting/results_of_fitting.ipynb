{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 302,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import scipy.interpolate as sci"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "def mse(value_true, value_prediction):\n",
    "    return mean_squared_error(value_true, value_prediction)\n",
    "\n",
    "def rmse(value_true, value_prediction):\n",
    "    return mean_squared_error(value_true, value_prediction, squared=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read dataset from a path\n",
    "def read_dataset_single(path):\n",
    "    #returns a panda object with just the 3 columns Node, y, x\n",
    "    df = pd.read_csv(path, sep='\\t')\n",
    "    df = df[['Node Name', 'Total-time', 'Data Size']]\n",
    "    return df\n",
    "\n",
    "# read dataset from a list of paths\n",
    "def read_dataset_all(name_list):\n",
    "    # returns a panda object with all datasets combined\n",
    "    df_result = pd.DataFrame(['Node Name', 'Total-time', 'Data Size'])\n",
    "    \n",
    "    for path in name_list:\n",
    "        df_specific_result = read_dataset_single(path)\n",
    "        df_result = pd.concat([df_result, df_specific_result])\n",
    "        \n",
    "    return df_result\n",
    "\n",
    "\n",
    "# build a cleaned dataset with a minimum number of nodes, determined by the threshold\n",
    "def clean_data(df, threshold):\n",
    "    \n",
    "    nodename_counts = df['Node Name'].value_counts()\n",
    "    valid_nodenames = nodename_counts[nodename_counts >= threshold].index.tolist()\n",
    "    \n",
    "    return df[df['Node Name'].isin(valid_nodenames)]\n",
    "\n",
    "\n",
    "# returns array with all the unique nodenames\n",
    "def give_nodenames(df):\n",
    "    return np.unique(df['Node Name'].values)\n",
    "\n",
    "\n",
    "# returns just the x and y values for a Node as np.arrays\n",
    "# they are returned as sorted (by x) and unique\n",
    "# sort values (for easier fitting and interpolation)\n",
    "def give_x_and_y_per_node(df_general_result, name):\n",
    "\n",
    "    df = df_general_result[df_general_result['Node Name'] == name]\n",
    "    x, y = df['Data Size'].values, df['Total-time'].values\n",
    "    \n",
    "    unique_x, unique_indices = np.unique(x, return_index=True)\n",
    "    unique_y = y[unique_indices]\n",
    "\n",
    "    sorted_indices = np.argsort(unique_x)\n",
    "    \n",
    "    return unique_x[sorted_indices], unique_y[sorted_indices]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plotting Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_data_and_fitted_functions(x_values, y_values, function_to_plot, titel_name):\n",
    "    \n",
    "    fig, ax = plt.subplots()\n",
    "\n",
    "    # plot x,y\n",
    "    ax.scatter(x_values, y_values, label=\"Data Points\", color='b', marker='o')\n",
    "\n",
    "    # create estimations for plotting the function\n",
    "    x_range = np.linspace(min(x_values), max(x_values), 100)\n",
    "    y_range = function_to_plot(x_range)\n",
    "\n",
    "    ax.plot(x_range, y_range, label=\"function for estimation\", color='r')\n",
    "\n",
    "    ax.set_xlabel(\"X Values\")\n",
    "    ax.set_ylabel(\"Y Values\")\n",
    "    ax.set_title(titel_name)\n",
    "\n",
    "    ax.legend()\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Necessery Functions for Polyfit (poly1..4 and log1..4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for estimation of Polynominal\n",
    "def polynominal_estimation(x, coefficients):\n",
    "    return np.polyval(coefficients, x)\n",
    "\n",
    "# Curvefitting is optimized for log and exp functions\n",
    "# Polyfit is optimizied for polynominals\n",
    "# def log_polynominal_estimation(x, coefficients):\n",
    "#     return np.log(np.polyval(coefficients, x))\n",
    "\n",
    "# # for curve fitting\n",
    "# #--------polynominal----------\n",
    "def poly_1_curve(x, a, b):\n",
    "    return np.polyval([a,b], x)\n",
    "\n",
    "def poly_2_curve(x, a, b, c):\n",
    "    return np.polyval([a,b,c], x)\n",
    "\n",
    "def poly_3_curve(x, a, b, c, d):\n",
    "    return np.polyval([a,b,c,d], x)\n",
    "\n",
    "def poly_4_curve(x, a, b, c, d, e):\n",
    "    return np.polyval([a,b,c,d,e], x)\n",
    "\n",
    "#----------log----------\n",
    "def log_1_curve(x, a, b):\n",
    "    return np.log(np.polyval([a,b], x))\n",
    "\n",
    "def log_2_curve(x, a, b, c):\n",
    "    return np.log(np.polyval([a,b,c], x))\n",
    "\n",
    "def log_3_curve(x, a, b, c, d):\n",
    "    return np.log(np.polyval([a,b,c,d], x))\n",
    "\n",
    "def log_4_curve(x, a, b, c, d, e):\n",
    "    return np.log(np.polyval([a,b,c,d,e], x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fitting Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.optimize import curve_fit\n",
    "\n",
    "\n",
    "#----------Fitting (Standart)----------\n",
    "def polynomial_fit(x, y, degree):\n",
    "    return np.polyfit(x, y, degree)\n",
    "\n",
    "# # basically same function, but for better understanding here\n",
    "# def log_polynominal_fitting(x, y_exp, degree):\n",
    "#     return np.polyfit(x, y_exp, degree)\n",
    "\n",
    "# deprecated Polynominal.fit is the new one\n",
    "#\n",
    "\n",
    "#----------Curve Fitting----------\n",
    "# for large datasets, u should give a rough guess to speed up the fitting\n",
    "# here we usually use the results from the previous interpolations\n",
    "def curve_fitting_coefficients(x_values, y_values, function, guess=''):\n",
    "    coeff, _ = curve_fit(function, x_values, y_values, p0=guess)\n",
    "    return coeff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_log(x_values, y_values, group_of_methods, Node, Dataset):\n",
    "    \n",
    "    list_of_functions = [log_1_curve, log_2_curve, log_3_curve, log_4_curve]\n",
    "    \n",
    "    n = len(group_of_methods['log']) +  len(group_of_methods['log_curve'])\n",
    "    \n",
    "    return_df = pd.DataFrame(columns=['Reference Genom', 'Node Name', 'prediction method', 'mse', 'rmse'])\n",
    "    ref_genom = np.repeat( a=Dataset, repeats=n)\n",
    "    n_name = np.repeat( a=Node, repeats=n)\n",
    "\n",
    "    method = np.empty(n, dtype = str)\n",
    "    mses = np.empty(n)\n",
    "    rmses = np.empty(n)\n",
    "\n",
    "    \n",
    "    m = len(group_of_methods['log'])\n",
    "    coeffs = np.empty(m)\n",
    "    \n",
    "    y_log = np.log(y_values)\n",
    "    \n",
    "    for i in group_of_methods['log']:\n",
    "        \n",
    "        coeff_ = np.polyfit(x=x_values, y=y_log, deg=i)\n",
    "        y_pred = np.polyval(coeff_, x_values)\n",
    "        method[i-1] = f\"{'Log_Polynominal '} {i}\"\n",
    "        mses[i-1] = np.exp(mse(y_log, y_pred))\n",
    "        rmses[i-1] = np.exp(rmse(y_log, y_pred))\n",
    "        coeffs[i-1] = coeff_\n",
    "\n",
    "        \n",
    "        \n",
    "    for i in group_of_methods['log_curve']:\n",
    "\n",
    "        coeff = curve_fitting_coefficients(x_values, y_log, list_of_functions[i-1], coeffs[i-1])\n",
    "        y_pred = np.polyval(coeff, x_values)\n",
    "        method[m+i-1] = f\"{'Log_curve '} {i}\"\n",
    "        mses[m+i-1] = np.exp(mse(y_log, y_pred))\n",
    "        rmses[m+i-1] = np.exp(rmse(y_log, y_pred))\n",
    "\n",
    "    return_df['Reference Genom'] = ref_genom\n",
    "    return_df['Node Name'] = n_name\n",
    "    return_df['prediction method'] = method\n",
    "    return_df['mse'] = mses\n",
    "    return_df['rmse'] = rmses\n",
    "    \n",
    "    return return_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_poly(x_values, y_values, group_of_methods, Node, Dataset):\n",
    "    \n",
    "    list_of_functions = [poly_1_curve, poly_2_curve, poly_3_curve, poly_4_curve]\n",
    "    \n",
    "    n = len(group_of_methods['poly']) +  len(group_of_methods['poly_curve'])\n",
    "    \n",
    "    return_df = pd.DataFrame(columns=['Reference Genom', 'Node Name', 'prediction method', 'mse', 'rmse'])\n",
    "    ref_genom = np.repeat( a=Dataset, repeats=n)\n",
    "    n_name = np.repeat( a=Node, repeats=n)\n",
    "\n",
    "    method = np.empty(n, dtype = str)\n",
    "    mses = np.empty(n)\n",
    "    rmses = np.empty(n)\n",
    "\n",
    "    m = len(group_of_methods['poly'])\n",
    "    coeffs = np.empty(m)\n",
    "    \n",
    "    for i in group_of_methods['poly']:\n",
    "        \n",
    "        coeff_ = np.polyfit(x=x_values, y=y_values, deg=i)\n",
    "        y_pred = np.polyval(coeff_, x_values)\n",
    "        method[i-1] = f\"{'Polynominal '} {i}\"\n",
    "        mses[i-1] = mse(y_values, y_pred)\n",
    "        rmses[i-1] = rmse(y_values, y_pred)\n",
    "        coeffs[i-1] = coeff_\n",
    "\n",
    "        \n",
    "        \n",
    "    for i in group_of_methods['poly_curve']:\n",
    "\n",
    "        coeff = curve_fitting_coefficients(x_values, y_values, list_of_functions[i-1], coeffs[i-1])\n",
    "        y_pred = np.polyval(coeff, x_values)\n",
    "        method[m+i-1] = f\"{'Polynominal_curve '} {i}\"\n",
    "        mses[m+i-1] = mse(y_values, y_pred)\n",
    "        rmses[m+i-1] = rmse(y_values, y_pred)\n",
    "\n",
    "    return_df['Reference Genom'] = ref_genom\n",
    "    return_df['Node Name'] = n_name\n",
    "    return_df['prediction method'] = method\n",
    "    return_df['mse'] = mses\n",
    "    return_df['rmse'] = rmses\n",
    "    \n",
    "    return return_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Spline Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.interpolate as sci\n",
    "# more complicated than before, but the old stuff was deprecated and mostly legacy code\n",
    "# here we can also give us the spline functions and how they look\n",
    "# I implemented the fitting and the interpolation\n",
    "\n",
    "# for Spline prediction we need some help values\n",
    "\n",
    "# gives me t_knots as a regular intervall between start and endpoint with k+1 regularity\n",
    "# if there are too few data points it just takes them in an uniform distance.\n",
    "# def get_t_Knots_regular(x_values, k_degree):\n",
    "    \n",
    "#     r = (2 * k_degree + 1) if (len(x_values) > 2 * (k_degree + 1)) else len(x_values)\n",
    "    \n",
    "#     return np.linspace(x_values[0], x_values[-1], r)\n",
    "\n",
    "\n",
    "\n",
    "# import UnivariateSpline\n",
    "# scipy.interpolate import make_smoothing_spline\n",
    "# for smoothing\n",
    "def get_s_smoothing_approximation_1(y_values):\n",
    "    return len(y_values) - np.sqrt(2 * len(y_values))\n",
    "\n",
    "def get_s_smoothing_approximation_2(y_values):\n",
    "    return len(y_values) * np.var(y_values)\n",
    "\n",
    "\n",
    "#----------Spline with smoothing----------\n",
    "# create spline object with smoothing build in (less knots)\n",
    "# def spline_fitting_with_smoothing_1(x_values, y_values, degree, smooth):\n",
    "#     return sci.UnivariateSpline(x_values, y_values, k=degree, s=smooth)\n",
    "\n",
    "# needs weights or smoothing condition\n",
    "# sci.splrep()\n",
    "\n",
    "# need knots t\n",
    "# sci.make_lsq_spline()\n",
    "    \n",
    "#----------Fitting----------\n",
    "\n",
    "# make_smoothing_spline\n",
    "# needs x,y\n",
    "# make_smoothing_spline(x, y, w=None, lam=None)\n",
    "# returns BSpline object\n",
    "\n",
    "# relevant results for a spline\n",
    "# Knots, coefficient, degree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Smoothing Coniditions explanation\n",
    "https://en.wikipedia.org/wiki/Smoothing_spline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_sspline(x_values, y_values, group_of_methods, Node, Dataset):\n",
    "    # make_smoothing_spline\n",
    "    # needs x,y\n",
    "    # make_smoothing_spline(x, y, w=None, lam=None)\n",
    "    # returns BSpline object\n",
    "    \n",
    "    \n",
    "    return_df = pd.DataFrame(columns=['Reference Genom', 'Node Name', 'prediction method', 'mse', 'rmse'])\n",
    "    ref_genom = np.repeat( a=Dataset, repeats=1)\n",
    "    n_name = np.repeat( a=Node, repeats=1)\n",
    "\n",
    "    method = np.empty(1, dtype = str)\n",
    "    mses = np.empty(1)\n",
    "    rmses = np.empty(1)\n",
    "    \n",
    "    bspline = sci.make_smoothing_spline(x=x_values, y=y_values)\n",
    "    y_pred = bspline(x=x_values)\n",
    "    method[0] = f\"{'Smoothing Spline'}\"\n",
    "    mses[0] = mse(y_values, y_pred)\n",
    "    rmses[0] = rmse(y_values, y_pred)\n",
    "    \n",
    "    return_df['Reference Genom'] = ref_genom\n",
    "    return_df['Node Name'] = n_name\n",
    "    return_df['prediction method'] = method\n",
    "    return_df['mse'] = mses\n",
    "    return_df['rmse'] = rmses\n",
    "    \n",
    "    return return_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_uspline(x_values, y_values, group_of_methods, Node, Dataset):\n",
    "    # univariantspline\n",
    "    # needs x,y, w or s, k\n",
    "    # UnivariateSpline(x, y, w=None, bbox=[None, None], k=3, s=None, ext=0, check_finite=False)\n",
    "    # is an univariantspline object\n",
    "    \n",
    "    return_df = pd.DataFrame(columns=['Reference Genom', 'Node Name', 'prediction method', 'mse', 'rmse'])\n",
    "    \n",
    "    n = len(group_of_methods['univariant_spline_1']) +  len(group_of_methods['univariant_spline_2'])\n",
    "    ref_genom = np.repeat( a=Dataset, repeats=n)\n",
    "    n_name = np.repeat( a=Node, repeats=n)\n",
    "\n",
    "    method = np.empty(n, dtype = str)\n",
    "    mses = np.empty(n)\n",
    "    rmses = np.empty(n)\n",
    "    \n",
    "    s1 = get_s_smoothing_approximation_1(y_values)\n",
    "    s2 = get_s_smoothing_approximation_2(y_values)\n",
    "    m = len(group_of_methods['univariant_spline_1'])\n",
    "    \n",
    "    for i in group_of_methods['univariant_spline_1']:\n",
    "        uspline = sci.UnivariateSpline(x=x_values, y=y_values, s=s2, k=i)\n",
    "        method[i-1] = f\"{'Univariatn Spline smoothing approximation 1 with degree '} {i} \"\n",
    "        y_pred = uspline(x=x_values)\n",
    "        mses[i-1] = mse(y_values, y_pred)\n",
    "        rmses[i-1] = rmse(y_values, y_pred)\n",
    "    \n",
    "    \n",
    "    for i in group_of_methods['univariant_spline_2']:\n",
    "        uspline = sci.UnivariateSpline(x=x_values, y=y_values, s=s1, k=i)\n",
    "        method[m+i-1] = f\"{'Univariatn Spline smoothing approximation 2 with degree '} {i} \"\n",
    "        y_pred = uspline(x=x_values)\n",
    "        mses[m+i-1] = mse(y_values, y_pred)\n",
    "        rmses[m+i-1] = rmse(y_values, y_pred)\n",
    "    \n",
    "\n",
    "    \n",
    "    return_df['Reference Genom'] = ref_genom\n",
    "    return_df['Node Name'] = n_name\n",
    "    return_df['prediction method'] = method\n",
    "    return_df['mse'] = mses\n",
    "    return_df['rmse'] = rmses\n",
    "    \n",
    "    return return_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_splinerep(x_values, y_values, group_of_methods, Node, Dataset):\n",
    "    # splrep\n",
    "    # needs x,y, w or s, k\n",
    "    # splrep(x, y, w=None, xb=None, xe=None, k=3, task=0, s=None, t=None, full_output=0, per=0, quiet=1)\n",
    "    # returns parameters for a bsplineobject\n",
    "\n",
    "    return_df = pd.DataFrame(columns=['Reference Genom', 'Node Name', 'prediction method', 'mse', 'rmse'])\n",
    "    \n",
    "    n = len(group_of_methods['spline_approximation_1']) +  len(group_of_methods['spline_approximation_2'])\n",
    "    ref_genom = np.repeat( a=Dataset, repeats=n)\n",
    "    n_name = np.repeat( a=Node, repeats=n)\n",
    "\n",
    "    method = np.empty(n, dtype = str)\n",
    "    mses = np.empty(n)\n",
    "    rmses = np.empty(n)\n",
    "    \n",
    "    s1 = get_s_smoothing_approximation_1(y_values)\n",
    "    s2 = get_s_smoothing_approximation_2(y_values)\n",
    "    m = len(group_of_methods['spline_approximation_1'])\n",
    "    \n",
    "    for i in group_of_methods['spline_approximation_1']:\n",
    "        tck =  sci.splrep(x=x_values, y=y_values, s=s1, k=i)\n",
    "        method[i-1] = f\"{'Generell Spline approximation smoothing s1 with degree '} {i} \"\n",
    "        y_pred = sci.splev(x=x_values, tck=tck)\n",
    "        mses[i-1] = mse(y_values, y_pred)\n",
    "        rmses[i-1] = rmse(y_values, y_pred)\n",
    "    \n",
    "    \n",
    "    for i in group_of_methods['spline_approximation_2']:\n",
    "        tck =  sci.splrep(x=x_values, y=y_values, s=s2, k=i)\n",
    "        method[m+i-1] = f\"{'Generell Spline approximation smoothing s2 with degree '} {i} \"\n",
    "        y_pred = sci.splev(x=x_values, tck=tck)\n",
    "        mses[m+i-1] = mse(y_values, y_pred)\n",
    "        rmses[m+i-1] = rmse(y_values, y_pred)\n",
    "    \n",
    "\n",
    "    return_df['Reference Genom'] = ref_genom\n",
    "    return_df['Node Name'] = n_name\n",
    "    return_df['prediction method'] = method\n",
    "    return_df['mse'] = mses\n",
    "    return_df['rmse'] = rmses\n",
    "    \n",
    "    return return_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "metadata": {},
   "outputs": [],
   "source": [
    "# returns a dict with the min_mse, best method, coefficients of the method and function of the method\n",
    "def comparing_fitting_methods(x_values, y_values, group_of_methods, Node, Dataset):\n",
    "\n",
    "    return_df = pd.DataFrame(columns=['Reference Genom', 'Node Name', 'prediction method', 'mse', 'rmse'])\n",
    "\n",
    "    poly = False\n",
    "    log = False\n",
    "    poly_curve = False\n",
    "    log_curve = False\n",
    "    s_spline = False\n",
    "    u_spline_1 = False\n",
    "    u_spline_2 = False\n",
    "    splrep_1 = False\n",
    "    splrep_2 = False\n",
    "\n",
    "\n",
    "    for key in group_of_methods.keys():\n",
    "        poly |= key == 'poly'\n",
    "        log |= key == 'log'\n",
    "        poly_curve |= key == 'poly_curve'\n",
    "        log_curve |= key == 'log_curve'\n",
    "        s_spline |= key == 'smoothing_spline'\n",
    "        u_spline_1 |= key == 'univariant_spline_1'\n",
    "        u_spline_2 |= key == 'univariant_spline_2'\n",
    "        splrep_1 |= key == 'spline_approximation_1'\n",
    "        splrep_2 |= key == 'spline_approximation_2'\n",
    "\n",
    "\n",
    "\n",
    "    if poly or poly_curve:\n",
    "        tmp_df = make_poly(x_values, y_values, group_of_methods, Node, Dataset)\n",
    "        return_df = pd.concat(return_df, tmp_df)        \n",
    "        \n",
    "    if log or log_curve:\n",
    "        tmp_df = make_log(x_values, y_values, group_of_methods, Node, Dataset)\n",
    "        return_df = pd.concat(return_df, tmp_df)   \n",
    "        \n",
    "    if s_spline:\n",
    "        tmp_df = make_sspline(x_values, y_values, group_of_methods, Node, Dataset)\n",
    "        return_df = pd.concat(return_df, tmp_df)     \n",
    "        \n",
    "    if u_spline_1 or u_spline_2:\n",
    "        tmp_df = make_uspline(x_values, y_values, group_of_methods, Node, Dataset)\n",
    "        return_df = pd.concat(return_df, tmp_df)   \n",
    "        \n",
    "    if splrep_1 or splrep_2:\n",
    "        tmp_df = make_splinerep(x_values, y_values, group_of_methods, Node, Dataset)\n",
    "        return_df = pd.concat(return_df, tmp_df)\n",
    "\n",
    "    return return_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_solution_overview_by_genome(path_df, group_of_methods, Dataset):\n",
    "    file = pd.ExcelFile(path_df)\n",
    "    df = pd.read_excel(file,'General-Results')\n",
    "    # df = read_dataset_all(list_of_Paths)\n",
    "    # df = clean_data(df, threshold)\n",
    "    nodenames = give_nodenames(df)\n",
    "    return_df = pd.DataFrame(columns=['Reference Genom', 'Node Name', 'prediction method', 'mse', 'rmse'])\n",
    "\n",
    "    # result_df = pd.DataFrame(index=nodenames)\n",
    "    for name in nodenames:\n",
    "        x_sorted, y_sorted = give_x_and_y_per_node(df, name)\n",
    "        tmp_df = comparing_fitting_methods(x_sorted, y_sorted, group_of_methods, name, Dataset)\n",
    "        return_df = pd.concat(return_df, tmp_df) \n",
    "        \n",
    "    name_csv = Path(Dataset + '.csv')\n",
    "    name_xlsx = Path(Dataset + '.xlsx')\n",
    "    return_df.to_csv('test.csv')    \n",
    " \n",
    "    with pd.ExcelWriter('test.xlsx') as writer:\n",
    "\n",
    "        return_df.to_excel(writer)\n",
    "    \n",
    "    print(return_df)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Necessary Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "could not convert string to float: 'Polynominal  1'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m/Users/manuez42/Desktop/fonda/A2-job-granularity/MG-HIBF/Fitting/results_of_fitting.ipynb Zelle 23\u001b[0m line \u001b[0;36m4\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/manuez42/Desktop/fonda/A2-job-granularity/MG-HIBF/Fitting/results_of_fitting.ipynb#X30sZmlsZQ%3D%3D?line=41'>42</a>\u001b[0m threshold\u001b[39m=\u001b[39m\u001b[39m10\u001b[39m \u001b[39m#what is the minimum number of datapoints to consider per Node\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/manuez42/Desktop/fonda/A2-job-granularity/MG-HIBF/Fitting/results_of_fitting.ipynb#X30sZmlsZQ%3D%3D?line=43'>44</a>\u001b[0m \u001b[39mfor\u001b[39;00m p, name \u001b[39min\u001b[39;00m \u001b[39mzip\u001b[39m(data_paths, names):\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/manuez42/Desktop/fonda/A2-job-granularity/MG-HIBF/Fitting/results_of_fitting.ipynb#X30sZmlsZQ%3D%3D?line=44'>45</a>\u001b[0m     build_solution_overview_by_genome(p, group_of_methods, name)\n",
      "\u001b[1;32m/Users/manuez42/Desktop/fonda/A2-job-granularity/MG-HIBF/Fitting/results_of_fitting.ipynb Zelle 23\u001b[0m line \u001b[0;36m1\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/manuez42/Desktop/fonda/A2-job-granularity/MG-HIBF/Fitting/results_of_fitting.ipynb#X30sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m \u001b[39mfor\u001b[39;00m name \u001b[39min\u001b[39;00m nodenames:\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/manuez42/Desktop/fonda/A2-job-granularity/MG-HIBF/Fitting/results_of_fitting.ipynb#X30sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m     x_sorted, y_sorted \u001b[39m=\u001b[39m give_x_and_y_per_node(df, name)\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/manuez42/Desktop/fonda/A2-job-granularity/MG-HIBF/Fitting/results_of_fitting.ipynb#X30sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m     tmp_df \u001b[39m=\u001b[39m comparing_fitting_methods(x_sorted, y_sorted, group_of_methods, name, Dataset)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/manuez42/Desktop/fonda/A2-job-granularity/MG-HIBF/Fitting/results_of_fitting.ipynb#X30sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m     return_df \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mconcat(return_df, tmp_df) \n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/manuez42/Desktop/fonda/A2-job-granularity/MG-HIBF/Fitting/results_of_fitting.ipynb#X30sZmlsZQ%3D%3D?line=14'>15</a>\u001b[0m name_csv \u001b[39m=\u001b[39m Path(Dataset \u001b[39m+\u001b[39m \u001b[39m'\u001b[39m\u001b[39m.csv\u001b[39m\u001b[39m'\u001b[39m)\n",
      "\u001b[1;32m/Users/manuez42/Desktop/fonda/A2-job-granularity/MG-HIBF/Fitting/results_of_fitting.ipynb Zelle 23\u001b[0m line \u001b[0;36m3\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/manuez42/Desktop/fonda/A2-job-granularity/MG-HIBF/Fitting/results_of_fitting.ipynb#X30sZmlsZQ%3D%3D?line=25'>26</a>\u001b[0m     splrep_2 \u001b[39m|\u001b[39m\u001b[39m=\u001b[39m key \u001b[39m==\u001b[39m \u001b[39m'\u001b[39m\u001b[39mspline_approximation_2\u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/manuez42/Desktop/fonda/A2-job-granularity/MG-HIBF/Fitting/results_of_fitting.ipynb#X30sZmlsZQ%3D%3D?line=29'>30</a>\u001b[0m \u001b[39mif\u001b[39;00m poly \u001b[39mor\u001b[39;00m poly_curve:\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/manuez42/Desktop/fonda/A2-job-granularity/MG-HIBF/Fitting/results_of_fitting.ipynb#X30sZmlsZQ%3D%3D?line=30'>31</a>\u001b[0m     tmp_df \u001b[39m=\u001b[39m make_poly(x_values, y_values, group_of_methods, Node, Dataset)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/manuez42/Desktop/fonda/A2-job-granularity/MG-HIBF/Fitting/results_of_fitting.ipynb#X30sZmlsZQ%3D%3D?line=31'>32</a>\u001b[0m     return_df \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mconcat(return_df, tmp_df)        \n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/manuez42/Desktop/fonda/A2-job-granularity/MG-HIBF/Fitting/results_of_fitting.ipynb#X30sZmlsZQ%3D%3D?line=33'>34</a>\u001b[0m \u001b[39mif\u001b[39;00m log \u001b[39mor\u001b[39;00m log_curve:\n",
      "\u001b[1;32m/Users/manuez42/Desktop/fonda/A2-job-granularity/MG-HIBF/Fitting/results_of_fitting.ipynb Zelle 23\u001b[0m line \u001b[0;36m2\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/manuez42/Desktop/fonda/A2-job-granularity/MG-HIBF/Fitting/results_of_fitting.ipynb#X30sZmlsZQ%3D%3D?line=19'>20</a>\u001b[0m coeff_ \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mpolyfit(x\u001b[39m=\u001b[39mx_values, y\u001b[39m=\u001b[39my_values, deg\u001b[39m=\u001b[39mi)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/manuez42/Desktop/fonda/A2-job-granularity/MG-HIBF/Fitting/results_of_fitting.ipynb#X30sZmlsZQ%3D%3D?line=20'>21</a>\u001b[0m y_pred \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mpolyval(coeff_, x_values)\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/manuez42/Desktop/fonda/A2-job-granularity/MG-HIBF/Fitting/results_of_fitting.ipynb#X30sZmlsZQ%3D%3D?line=21'>22</a>\u001b[0m method[i\u001b[39m-\u001b[39;49m\u001b[39m1\u001b[39;49m] \u001b[39m=\u001b[39m \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39mPolynominal \u001b[39m\u001b[39m'\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m \u001b[39m\u001b[39m{\u001b[39;00mi\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/manuez42/Desktop/fonda/A2-job-granularity/MG-HIBF/Fitting/results_of_fitting.ipynb#X30sZmlsZQ%3D%3D?line=22'>23</a>\u001b[0m mses[i\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m] \u001b[39m=\u001b[39m mse(y_values, y_pred)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/manuez42/Desktop/fonda/A2-job-granularity/MG-HIBF/Fitting/results_of_fitting.ipynb#X30sZmlsZQ%3D%3D?line=23'>24</a>\u001b[0m rmses[i\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m] \u001b[39m=\u001b[39m rmse(y_values, y_pred)\n",
      "\u001b[0;31mValueError\u001b[0m: could not convert string to float: 'Polynominal  1'"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# path_finals = [Path(\"/Users/manuez42/Desktop/fonda/A2-job-granularity/MG-HIBF/general_results_fonda/general_results_viral500m.tsv\"),\n",
    "#                Path(\"/Users/manuez42/Desktop/fonda/A2-job-granularity/MG-HIBF/general_results_fonda/general_results_archea1.4g.tsv\"),\n",
    "#                Path(\"/Users/manuez42/Desktop/fonda/A2-job-granularity/MG-HIBF/general_results_fonda/general_results_bacteria30g.tsv\"),\n",
    "#                Path(\"/Users/manuez42/Desktop/fonda/A2-job-granularity/MG-HIBF/general_results_fonda/general_results_bacteria58g.tsv\"),\n",
    "#                Path(\"/Users/manuez42/Desktop/fonda/A2-job-granularity/MG-HIBF/general_results_fonda/general_results_bacteria88g.tsv\"),\n",
    "#                Path(\"/Users/manuez42/Desktop/fonda/A2-job-granularity/MG-HIBF/general_results_fonda/general_results_bacteria125g.tsv\")]\n",
    "\n",
    "# name_list = [\"viral500m\", \"archea1.4g\", \"bacteria30g\", \"bacteria58\", \"bacteria88\", \"bacteria125\"]\n",
    "data_paths = [Path(\"../general_results_fonda/selected_data/results_archea1.4g_8nodes.xlsx\"),\n",
    "              Path(\"../general_results_fonda/selected_data/results_archea1.4g_24nodes.xlsx\"),\n",
    "              Path(\"../general_results_fonda/selected_data/results_bacteria30g_8nodes.xlsx\"),\n",
    "              Path(\"../general_results_fonda/selected_data/results_bacteria30g_24nodes.xlsx\"),\n",
    "              Path(\"../general_results_fonda/selected_data/results_bacteria58g_8nodes.xlsx\"),\n",
    "              Path(\"../general_results_fonda/selected_data/results_bacteria58g_24nodes.xlsx\"),\n",
    "              Path(\"../general_results_fonda/selected_data/results_bacteria88g_8nodes.xlsx\"),\n",
    "              Path(\"../general_results_fonda/selected_data/results_bacteria88g_24nodes.xlsx\")\n",
    "]\n",
    "\n",
    "names = ['archea1.4g_8nodes', 'archea1.4g_24nodes',\n",
    "         'bacteria30g_8nodes', 'bacteria30g_24nodes',\n",
    "         'bacteria58g_8nodes', 'bacteria58g_24nodes',\n",
    "         'bacteria88g_8nodes', 'bacteria88g_24nodes'\n",
    "]\n",
    "\n",
    "group_of_methods = {\n",
    "        # define here what you want\n",
    "        'poly' : [1,2,3], #polynominal fitting, with degrees\n",
    "        'poly_curve' : [1,2,3], #polynominal curve fitting, with degrees\n",
    "        'log' : [1,2,3], #logarithmic fitting, with degrees\n",
    "        'log_curve': [1,2,3], #logarithmic curvefitting, with degrees\n",
    "        'smoothing_spline' : [1], #smoothing spline, finds a smooth spline with a degree\n",
    "        'univariant_spline_1': [1,2,3], #makes an univariant spline (same length of knots), with degree\n",
    "        'univariant_spline_2': [1,2,3], #makes an univariant spline (same length of knots), with degree\n",
    "        'spline_approximation_1': [1,2,3], #makes a spline approximation\n",
    "        'spline_approximation_2': [1,2,3] #makes a spline approximation\n",
    "    }\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "threshold=10 #what is the minimum number of datapoints to consider per Node\n",
    "\n",
    "for p, name in zip(data_paths, names):\n",
    "    build_solution_overview_by_genome(p, group_of_methods, name)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
