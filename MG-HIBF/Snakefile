configfile: "config.yaml"

import csv
import random
from collections import defaultdict

"""
buidling the bins
--> bin_id, filename
"""
num_bins = 0 # will be read implicitly from the bins file
bins = defaultdict(lambda: [])

with open("data/bins.tsv", "r") as f:
    reader = csv.reader(f, delimiter='\t')

    for row in reader:
        filename = row[0]
        bin_id = int(row[1])
        bins[bin_id].append(filename)
        num_bins = max(num_bins, bin_id + 1)

if list(range(num_bins)) != list(bins.keys()):
    raise RuntimeError("Error bins.tsv")

bin_ids = range(num_bins)


"""
buidling the nodelist and matching it to the bins
--> bin_id, nodename
"""
cmd = ["bash", "-c", "sinfo --long --Node | grep -P mix | grep -P small | awk '{print $1}' >> nodelist.csv"]
subprocess.run(cmd)
list_of_nodes = []
nodes = {}

with open("nodelist.csv", "r") as f:
    reader = csv.reader(f, delimiter=',')

    for row in reader:
        list_of_nodes.append(row[0])

for i in bin_ids:
    nodes[i] = random.choice(list_of_nodes)


with open("nodes.csv", "w+") as f:
    writer = csv.writer(f, delimiter=',')
    for b, node in nodes.items():
        writer.writerow( [b, node] )

genome_bin_files = expand("data/genome_bins/bin_{bin_id}.fasta", bin_id=bin_ids)
distributed_read_files = expand("data/distributed_reads/bin_{bin_id}.fastq", bin_id=bin_ids)


"""
###you now have as items###
- num_bins :: int
number of total bins 

- bins :: dict{bin_id : list}
dict of all bins (0..n) with the location(s) in the list

- bin_ids :: list
a list of all bin_id's

- list_of_nodes :: list
a list of all the available nodes

- nodes :: dict{bin_id : nodename}
dict where the bin_id is located to a nodename

- genome_bin_files :: list
list of alle the genom files in the bins

- distributed_read_files :: list
list of alle the distributet read files in the bins
"""

rule all:
    input:
        #expand("data/indices/bin{bin_id}_index", bin_id=bin_ids)
        expand("data/mapped_reads/bin_{bin_id}.sam", bin_id=bin_ids)
        # "data/mapped_reads/all.bam"
    # output:
    #     expand("data/mapped_reads/bin_{bin_id}.sam", bin_id=bin_ids)
    resources:
        nodelist = random.choice(list_of_nodes)
    shell:
        "echo {input}"

# TODO: something like this
# rule cplex_model:
#     input:
#         "all the genomes"
#     output:
#         "bins.tsv"

#create one fasta file out of the fasta files in the bin
rule create_bin_file:
    input:
        lambda wildcards: bins[int(wildcards.bin_id)]
    output:
        temp("data/genome_bins/bin_{bin_id}.fasta")
    resources:
        nodelist = lambda wildcards: nodes[int(wildcards.bin_id)]
    shell:
        "cat {input} > {output}"

num_threads = config["threads"]

include: "modules/prefilter.smk"
include: "modules/readmapping.smk"
#include: "modules/postprocessing.smk"