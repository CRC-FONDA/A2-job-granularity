#-----------------------------
#
# configfile
# & wildcards
# & imports
# & helpfunctions
#
#-----------------------------

configfile: "config.yaml"

#-----------------------------

bin_nodes_dic = defaultdict(lambda: [])
filepaths_binsn = defaultdict(lambda: [])
nodelist = []
# list_of_chromosomes = defaultdict(lambda: [])

#-----------------------------

import os
import csv
import subprocess
from pathlib import Path
from collections import defaultdict

#-----------------------------

def create_bins_file(path_to_data, nr_bins, path_to_working_dir):

    fasta_file_endings = [".fa", ".fna", ".fasta", "fastqc"]

    is_fasta_file = lambda f: any(f.endswith(end) for end in fasta_file_endings)
    fasta_filenames = filter(lambda f: is_fasta_file(f), os.listdir(path_to_data))

    to_path = lambda filename: os.path.join(path_to_data, filename)
    fasta_paths = map(to_path, fasta_filenames)

    binstsv = os.join.path(path_to_working_dir,"bins.tsv")
    with open(binstsv, "w+") as f:
        writer = csv.writer(f, delimiter='\t')
        for i, fasta_path in enumerate(fasta_paths):
            writer.writerow( [fasta_path , (i % nr_bins)] )

#-----------------------------


def filling_bins(path_to_working_dir, filepaths_bins):

    binstsv = os.path.join(path_to_working_dir,"bins.tsv")
    with open(binstsv, "r") as f:
            reader = csv.reader(f, delimiter='\t')

            for row in reader:
                filename = row[0]
                bin_id = int(row[1])
                filepaths_bins[bin_id].append(filename)
        
        for bin_id in bin_list:
            bin_dir = os.path.join(path_to_working_dir,f"bin_{bin_id}")
            os.makedirs(bin_dir, exist_ok=True)  # Create directory if it doesn't exist
            
            joined_fasta = os.path.join(bin_dir, f'all_{bin_id}.fasta')
            
            for file in filepaths_bins[bin_id]:
                os.system(f"cat {file} > {joined_fasta}")

    return filepaths_bins


#-----------------------------
#
# invokes all
#
#-----------------------------

rule make_all:
	input:
		expand("data/bin_{i}/Haplotypes/Annotation.vcf", i=range(config['number_of_bins']))
	shell:
		"echo 'Done'"


#-----------------------------
#
# preparing the major steps
#
#-----------------------------

rule create_general_files:
    output:
        "data/bins.tsv",
        "data/nodes.csv",
    # resources:
    #     nodes = config['number_of_nodes']
    params:
        data = config['path_to_reads'],
        bins = config['number_of_bins']
        work = config['working_dir']
    run:
        create_bins({params.data}, {params.bins}, {params.work})
        shell(f"sinfo --long --Node | grep -P 'mix|idle' | grep -P big | awk '{{print $1}}' > " + {params.work} + "/nodes.csv")


rule copying_data_to_nodes:
    input:
        "data/general/bins.tsv",
    output:
        expand("data/bin_{i}", i=range({params.bins}))
    params:
        bins = config['number_of_bins']
        work = config['working_dir']
    resources:
        # nodes = bin_nodes_dic[i],
        # or
        nodes = config['number_of_nodes']
        # nodelist = bin_nodes_dic[snakemake.job_id]
    run:
        filling_bins({params.work}, filepaths_bins)


#-----------------------------
#
# the three mayor steps
#
#-----------------------------
include: "rules/readmapping.smk"
include: "rules/collecting.smk"
include: "rules/annotating.smk"
